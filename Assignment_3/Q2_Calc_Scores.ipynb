{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8137851,"sourceType":"datasetVersion","datasetId":4810920}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import nltk\nfrom nltk.translate.bleu_score import sentence_bleu","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-17T15:40:47.959376Z","iopub.execute_input":"2024-04-17T15:40:47.959935Z","iopub.status.idle":"2024-04-17T15:40:49.922153Z","shell.execute_reply.started":"2024-04-17T15:40:47.959905Z","shell.execute_reply":"2024-04-17T15:40:49.921014Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"pip install rouge","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:40:49.923485Z","iopub.execute_input":"2024-04-17T15:40:49.924096Z","iopub.status.idle":"2024-04-17T15:41:01.573720Z","shell.execute_reply.started":"2024-04-17T15:40:49.924055Z","shell.execute_reply":"2024-04-17T15:41:01.572368Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: rouge in /opt/conda/lib/python3.10/site-packages (1.0.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from rouge import Rouge\nimport nltk\nfrom nltk.translate.bleu_score import corpus_bleu","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:42:24.773925Z","iopub.execute_input":"2024-04-17T15:42:24.774345Z","iopub.status.idle":"2024-04-17T15:42:24.782262Z","shell.execute_reply.started":"2024-04-17T15:42:24.774313Z","shell.execute_reply":"2024-04-17T15:42:24.781371Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def calc_scores(gt,translation):\n    \n    rouge = Rouge()\n    scores = rouge.get_scores(translation,gt, avg=True)\n    for k,v in scores.items():\n        print(k,\":\", v)\n    bleu_score = corpus_bleu(translation, gt)\n    print(\"BLEU Score:\", bleu_score)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:40:08.972132Z","iopub.execute_input":"2024-04-17T16:40:08.972535Z","iopub.status.idle":"2024-04-17T16:40:08.979364Z","shell.execute_reply.started":"2024-04-17T16:40:08.972506Z","shell.execute_reply":"2024-04-17T16:40:08.978248Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"# **NLLB Scores**","metadata":{}},{"cell_type":"markdown","source":"**English to Hindi**","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/models/model1/en_to_hi1.txt', 'r') as f1:\n    translated = f1.readlines()\n\nwith open('/kaggle/input/models/model1/sentences_hi.txt', 'r') as f2:\n    ground_truth = f2.readlines()\n\ncalc_scores(translated[:50] ,ground_truth[:50] )","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:14:19.387391Z","iopub.execute_input":"2024-04-17T16:14:19.387748Z","iopub.status.idle":"2024-04-17T16:14:20.111982Z","shell.execute_reply.started":"2024-04-17T16:14:19.387721Z","shell.execute_reply":"2024-04-17T16:14:20.110595Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"rouge-1 : {'r': 0.6122622997917117, 'p': 0.588041304580913, 'f': 0.5963499680456849}\nrouge-2 : {'r': 0.38895429350491256, 'p': 0.369503236106211, 'f': 0.37617970327413686}\nrouge-l : {'r': 0.5705566949390479, 'p': 0.5488443549926589, 'f': 0.5560762476109874}\nBLEU Score: 0.7553460611709097\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Hindi to English**","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/models/model1/hi_to_en1.txt', 'r') as f1:\n    translated = f1.readlines()\n\nwith open('/kaggle/input/models/model1/sentences_en.txt', 'r') as f2:\n    ground_truth = f2.readlines()\n\ncalc_scores(translated[:50] ,ground_truth[:50] )","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:14:22.808721Z","iopub.execute_input":"2024-04-17T16:14:22.809734Z","iopub.status.idle":"2024-04-17T16:14:23.493036Z","shell.execute_reply.started":"2024-04-17T16:14:22.809702Z","shell.execute_reply":"2024-04-17T16:14:23.491925Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"rouge-1 : {'r': 0.6445021744681187, 'p': 0.6137158995115651, 'f': 0.6229431337079003}\nrouge-2 : {'r': 0.3814717656784221, 'p': 0.36572763782261025, 'f': 0.36989044234891644}\nrouge-l : {'r': 0.6218747145527331, 'p': 0.593235019280685, 'f': 0.6016730969151947}\nBLEU Score: 0.7185437313768158\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Gujrati to Hindi**","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/models/model1/guj_to_hin1.txt', 'r') as f1:\n    translated = f1.readlines()\n\nwith open('/kaggle/input/models/model1/sentences_hi.txt', 'r') as f2:\n    ground_truth = f2.readlines()\n\ncalc_scores(translated[:50] ,ground_truth[:50] )","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:14:24.271651Z","iopub.execute_input":"2024-04-17T16:14:24.272040Z","iopub.status.idle":"2024-04-17T16:14:24.973283Z","shell.execute_reply.started":"2024-04-17T16:14:24.272012Z","shell.execute_reply":"2024-04-17T16:14:24.972000Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"rouge-1 : {'r': 0.6137016412380192, 'p': 0.5958911721470277, 'f': 0.5996686170828448}\nrouge-2 : {'r': 0.384421605054732, 'p': 0.3724241104899001, 'f': 0.37451515957774256}\nrouge-l : {'r': 0.5881583255066228, 'p': 0.5706507652109686, 'f': 0.5744401255269151}\nBLEU Score: 0.7586074735035361\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Hindi to Gujrati**","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/models/model1/hin_to_guj1.txt', 'r') as f1:\n    translated = f1.readlines()\n\nwith open('/kaggle/input/models/model1/sentences_guj.txt', 'r') as f2:\n    ground_truth = f2.readlines()\n\ncalc_scores(translated[:50] ,ground_truth[:50] )","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:14:24.977261Z","iopub.execute_input":"2024-04-17T16:14:24.977581Z","iopub.status.idle":"2024-04-17T16:14:25.616211Z","shell.execute_reply.started":"2024-04-17T16:14:24.977557Z","shell.execute_reply":"2024-04-17T16:14:25.615208Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"rouge-1 : {'r': 0.5768699387128182, 'p': 0.5273330734303611, 'f': 0.5466075877445509}\nrouge-2 : {'r': 0.3045792890460073, 'p': 0.2792244360214948, 'f': 0.28865381413969776}\nrouge-l : {'r': 0.5516151029053508, 'p': 0.5054076594051018, 'f': 0.5232650029720527}\nBLEU Score: 0.7631422938702467\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **IndicTrans Scores**","metadata":{}},{"cell_type":"markdown","source":"**English to Hindi**","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/models/Model2/en_to_hi2.txt', 'r') as f1:\n    translated = f1.readlines()\n\nwith open('/kaggle/input/models/model1/sentences_hi.txt', 'r') as f2:\n    ground_truth = f2.readlines()\n\ncalc_scores(translated[:50] ,ground_truth[:50] )","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:14:25.617917Z","iopub.execute_input":"2024-04-17T16:14:25.618196Z","iopub.status.idle":"2024-04-17T16:14:26.349005Z","shell.execute_reply.started":"2024-04-17T16:14:25.618174Z","shell.execute_reply":"2024-04-17T16:14:26.347840Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"rouge-1 : {'r': 0.6266545646588049, 'p': 0.6338577333884914, 'f': 0.6261086736745579}\nrouge-2 : {'r': 0.39272711482990114, 'p': 0.3978144983459629, 'f': 0.3920938008238251}\nrouge-l : {'r': 0.5800958126093407, 'p': 0.5873217058089856, 'f': 0.5797794162814841}\nBLEU Score: 0.7503310841953775\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Hindi to English**","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/models/Model2/hi_to_en2.txt', 'r') as f1:\n    translated = f1.readlines()\n\nwith open('/kaggle/input/models/model1/sentences_en.txt', 'r') as f2:\n    ground_truth = f2.readlines()\n\ncalc_scores(translated[:50] ,ground_truth[:50] )","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:14:26.350918Z","iopub.execute_input":"2024-04-17T16:14:26.351290Z","iopub.status.idle":"2024-04-17T16:14:27.075773Z","shell.execute_reply.started":"2024-04-17T16:14:26.351262Z","shell.execute_reply":"2024-04-17T16:14:27.074775Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"rouge-1 : {'r': 0.6757936685366355, 'p': 0.6590498421427214, 'f': 0.6637713779850621}\nrouge-2 : {'r': 0.45372017391506547, 'p': 0.44649836055645037, 'f': 0.44719636980916133}\nrouge-l : {'r': 0.6599681443875819, 'p': 0.642557778650658, 'f': 0.6477238932854901}\nBLEU Score: 0.7134491809428187\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Gujrati to Hindi**","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/models/Model2/gu_to_hi2.txt', 'r') as f1:\n    translated = f1.readlines()\n\nwith open('/kaggle/input/models/model1/sentences_hi.txt', 'r') as f2:\n    ground_truth = f2.readlines()\n\ncalc_scores(translated[:50] ,ground_truth[:50] )","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:14:27.077125Z","iopub.execute_input":"2024-04-17T16:14:27.077459Z","iopub.status.idle":"2024-04-17T16:14:27.789363Z","shell.execute_reply.started":"2024-04-17T16:14:27.077431Z","shell.execute_reply":"2024-04-17T16:14:27.788370Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"rouge-1 : {'r': 0.592048309193565, 'p': 0.5888410792504887, 'f': 0.585670068001665}\nrouge-2 : {'r': 0.3637281977064081, 'p': 0.3617866363444167, 'f': 0.3592464020227966}\nrouge-l : {'r': 0.5610073368098816, 'p': 0.5580073960255011, 'f': 0.5550135653368927}\nBLEU Score: 0.7508583138300768\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Hindi to Gujrati**","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/models/Model2/hi_to_gu2.txt', 'r') as f1:\n    translated = f1.readlines()\n\nwith open('/kaggle/input/models/model1/sentences_guj.txt', 'r') as f2:\n    ground_truth = f2.readlines()\n\ncalc_scores(translated[:50] ,ground_truth[:50] )","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:14:27.791058Z","iopub.execute_input":"2024-04-17T16:14:27.791564Z","iopub.status.idle":"2024-04-17T16:14:28.474948Z","shell.execute_reply.started":"2024-04-17T16:14:27.791534Z","shell.execute_reply":"2024-04-17T16:14:28.473894Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"rouge-1 : {'r': 0.5620755426615233, 'p': 0.5438912144338515, 'f': 0.549331633619611}\nrouge-2 : {'r': 0.2888629757755144, 'p': 0.28154992491168956, 'f': 0.28284296096262673}\nrouge-l : {'r': 0.5448202064944225, 'p': 0.5267724125271238, 'f': 0.5322539348631197}\nBLEU Score: 0.7555177293231773\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **ChatGPT Scores**","metadata":{}},{"cell_type":"markdown","source":"**English to Hindi**","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/models/Model3/en_to_hi3.txt', 'r') as f1:\n    translated = f1.readlines()\n\nwith open('/kaggle/input/models/model1/sentences_hi.txt', 'r') as f2:\n    ground_truth = f2.readlines()\n\ncalc_scores(translated[:50] ,ground_truth[:50] )","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:14:28.476927Z","iopub.execute_input":"2024-04-17T16:14:28.477399Z","iopub.status.idle":"2024-04-17T16:14:29.184498Z","shell.execute_reply.started":"2024-04-17T16:14:28.477363Z","shell.execute_reply":"2024-04-17T16:14:29.182739Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"rouge-1 : {'r': 0.6296959456665341, 'p': 0.622497102078809, 'f': 0.6223093516763969}\nrouge-2 : {'r': 0.40307188413656303, 'p': 0.3954233055697587, 'f': 0.39653056953062743}\nrouge-l : {'r': 0.597940131104992, 'p': 0.5901690324029133, 'f': 0.5904884828307488}\nBLEU Score: 0.7530735588935642\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Hindi to English**","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/models/Model3/hi_to_en3.txt', 'r') as f1:\n    translated = f1.readlines()\n\nwith open('/kaggle/input/models/model1/sentences_en.txt', 'r') as f2:\n    ground_truth = f2.readlines()\n\ncalc_scores(translated[:50] ,ground_truth[:50] )","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:14:30.687041Z","iopub.execute_input":"2024-04-17T16:14:30.687442Z","iopub.status.idle":"2024-04-17T16:14:31.437238Z","shell.execute_reply.started":"2024-04-17T16:14:30.687413Z","shell.execute_reply":"2024-04-17T16:14:31.436329Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"rouge-1 : {'r': 0.5982687299501476, 'p': 0.5906013618304641, 'f': 0.5898594706029098}\nrouge-2 : {'r': 0.3423091061658164, 'p': 0.3387275560756378, 'f': 0.3372363679921774}\nrouge-l : {'r': 0.5678765347737621, 'p': 0.5613038567040115, 'f': 0.5601254398972491}\nBLEU Score: 0.7026825382774285\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Gujrati to Hindi**","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/models/Model3/gu_to_hi3.txt', 'r') as f1:\n    translated = f1.readlines()\n\nwith open('/kaggle/input/models/model1/sentences_hi.txt', 'r') as f2:\n    ground_truth = f2.readlines()\n\ncalc_scores(translated[:50] ,ground_truth[:50] )","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:14:31.887703Z","iopub.execute_input":"2024-04-17T16:14:31.888075Z","iopub.status.idle":"2024-04-17T16:14:32.629288Z","shell.execute_reply.started":"2024-04-17T16:14:31.888049Z","shell.execute_reply":"2024-04-17T16:14:32.627977Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"rouge-1 : {'r': 0.4736294139573653, 'p': 0.46549524168641826, 'f': 0.4660595996600764}\nrouge-2 : {'r': 0.22793011878908004, 'p': 0.22427372803059303, 'f': 0.22447280906676428}\nrouge-l : {'r': 0.4508092152056076, 'p': 0.44317265973010367, 'f': 0.4436131913452405}\nBLEU Score: 0.7409083788439963\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Hindi to Gujrati**","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/models/Model3/hi_to_gu3.txt', 'r') as f1:\n    translated = f1.readlines()\n\nwith open('/kaggle/input/models/model1/sentences_guj.txt', 'r') as f2:\n    ground_truth = f2.readlines()\n\ncalc_scores(translated[:50] ,ground_truth[:50] )","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:14:33.022762Z","iopub.execute_input":"2024-04-17T16:14:33.023153Z","iopub.status.idle":"2024-04-17T16:14:33.666897Z","shell.execute_reply.started":"2024-04-17T16:14:33.023125Z","shell.execute_reply":"2024-04-17T16:14:33.665757Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"rouge-1 : {'r': 0.4265267643433279, 'p': 0.408022073830359, 'f': 0.4128986090381582}\nrouge-2 : {'r': 0.18569732419806456, 'p': 0.17818252890899944, 'f': 0.1799191424229857}\nrouge-l : {'r': 0.41782366189022546, 'p': 0.39837712813278164, 'f': 0.4037956198219381}\nBLEU Score: 0.7509358713466501\n","output_type":"stream"}]}]}
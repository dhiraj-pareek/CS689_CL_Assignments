{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8122035,"sourceType":"datasetVersion","datasetId":4799318},{"sourceId":8122042,"sourceType":"datasetVersion","datasetId":4799324},{"sourceId":8128515,"sourceType":"datasetVersion","datasetId":4804190}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":null,"end_time":null,"environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-15T05:34:11.127048","version":"2.5.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Making Sentence Files**","metadata":{"papermill":{"duration":0.004182,"end_time":"2024-04-15T05:34:13.758606","exception":false,"start_time":"2024-04-15T05:34:13.754424","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import random\n\n# Load English lines\nwith open(\"/kaggle/input/dataset/test.en\", \"r\", encoding=\"utf-8\") as en_file:\n    en_lines = en_file.readlines()\n\n# Load Hindi lines\nwith open(\"/kaggle/input/dataset/test.hi\", \"r\", encoding=\"utf-8\") as hi_file:\n    hi_lines = hi_file.readlines()\n    \n# Load Gujrati lines\nwith open(\"/kaggle/input/dataset/test.gu\", \"r\", encoding=\"utf-8\") as guj_file:\n    guj_lines = guj_file.readlines()\n    \n# Generate random indices\nrandom_indices = random.sample(range(len(en_lines)), 1000)\nprint(len(set(random_indices)))\nen=[]\nhi=[]\ngu=[]\n\n# Create files to save English and Hindi sentences\nwith open(\"sentences_en.txt\", \"w\", encoding=\"utf-8\") as en_out_file, \\\n     open(\"sentences_hi.txt\", \"w\", encoding=\"utf-8\") as hi_out_file, \\\n     open(\"sentences_guj.txt\", \"w\", encoding=\"utf-8\") as guj_out_file:\n    for index in random_indices:\n        # Write English sentence to file\n        en_out_file.write(en_lines[index].strip() + \"\\n\")\n        en.append(en_lines[index].strip())\n        \n        # Write Hindi sentence to file\n        hi_out_file.write(hi_lines[index].strip() + \"\\n\")\n        hi.append(hi_lines[index].strip())\n        \n        # Write Hindi sentence to file\n        guj_out_file.write(guj_lines[index].strip() + \"\\n\")\n        gu.append(guj_lines[index].strip())","metadata":{"papermill":{"duration":0.05542,"end_time":"2024-04-15T05:34:13.817938","exception":false,"start_time":"2024-04-15T05:34:13.762518","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-16T09:24:03.188574Z","iopub.execute_input":"2024-04-16T09:24:03.188944Z","iopub.status.idle":"2024-04-16T09:24:03.284275Z","shell.execute_reply.started":"2024-04-16T09:24:03.188910Z","shell.execute_reply":"2024-04-16T09:24:03.283395Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"1000\n","output_type":"stream"}]},{"cell_type":"code","source":"print(random_indices)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T10:19:12.655551Z","iopub.execute_input":"2024-04-16T10:19:12.655912Z","iopub.status.idle":"2024-04-16T10:19:12.661005Z","shell.execute_reply.started":"2024-04-16T10:19:12.655882Z","shell.execute_reply":"2024-04-16T10:19:12.660157Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[1410, 965, 2009, 736, 1140, 2381, 1438, 1559, 1796, 441, 2114, 1435, 2168, 958, 44, 1437, 32, 2182, 2047, 749, 816, 707, 1879, 1127, 2354, 1519, 198, 1943, 1098, 37, 1013, 981, 245, 867, 2216, 108, 1071, 1650, 1363, 623, 2270, 287, 1506, 236, 1099, 1096, 1182, 765, 1129, 1549, 26, 493, 1505, 2247, 179, 652, 1367, 1256, 617, 1476, 1159, 347, 1193, 1503, 1110, 146, 1667, 1891, 1917, 451, 1743, 721, 843, 2176, 1536, 1860, 1947, 1228, 414, 1345, 1898, 1411, 1724, 1492, 1239, 1881, 1539, 1883, 1580, 868, 808, 1255, 2037, 1989, 818, 540, 224, 2026, 492, 500, 1888, 2042, 2004, 529, 1790, 2169, 1887, 1915, 1496, 1815, 1742, 156, 2276, 1543, 1296, 1893, 1295, 1894, 2338, 1095, 2170, 2385, 2085, 1699, 2253, 1076, 2035, 1633, 1106, 2206, 2104, 1510, 2210, 1300, 1045, 799, 82, 784, 528, 87, 2259, 1576, 1109, 1578, 2199, 1439, 527, 2221, 2367, 815, 350, 1662, 725, 295, 1080, 663, 1037, 1297, 1988, 470, 1684, 1, 2212, 2374, 361, 401, 331, 2313, 2237, 616, 759, 366, 321, 2005, 1075, 1050, 1187, 1242, 286, 70, 1087, 1338, 1599, 452, 1602, 1841, 315, 1043, 429, 1258, 1953, 1588, 2215, 476, 838, 119, 170, 346, 1391, 2018, 1460, 2136, 1348, 73, 508, 1853, 1823, 763, 2356, 2158, 1937, 562, 1794, 151, 1913, 288, 4, 133, 1289, 1728, 1534, 2105, 149, 118, 1380, 2051, 316, 2029, 2060, 293, 105, 488, 458, 1376, 2177, 1670, 506, 1613, 1866, 520, 588, 1798, 757, 1923, 251, 2109, 1882, 1340, 1212, 2093, 2197, 1629, 1260, 197, 1630, 2255, 1551, 2106, 1064, 1461, 268, 1729, 1886, 1023, 1497, 1736, 1058, 157, 1774, 976, 427, 326, 2096, 2285, 1991, 565, 1731, 735, 1896, 1721, 1062, 1149, 1726, 418, 731, 2341, 1469, 330, 567, 1531, 58, 478, 997, 1544, 502, 2056, 2252, 1306, 2128, 791, 1624, 1553, 1565, 1636, 2166, 994, 1136, 1445, 440, 669, 1269, 797, 252, 1454, 269, 649, 1015, 1425, 1093, 2119, 1969, 709, 1379, 1491, 1610, 1042, 775, 2138, 842, 2083, 2179, 357, 953, 2320, 1352, 1495, 1144, 449, 1554, 355, 1986, 2293, 24, 1185, 576, 837, 1835, 912, 1479, 64, 1945, 1108, 531, 844, 934, 2262, 2275, 524, 385, 79, 1614, 74, 954, 982, 1237, 959, 153, 737, 176, 977, 184, 412, 103, 2243, 1178, 49, 148, 303, 389, 551, 2003, 2372, 1661, 908, 75, 1069, 1696, 1571, 1360, 335, 468, 1168, 880, 1992, 2099, 1581, 966, 1001, 2070, 969, 1290, 97, 1718, 909, 1067, 1783, 381, 957, 1369, 1714, 320, 445, 800, 1229, 1309, 1753, 2209, 1272, 453, 822, 411, 360, 1529, 1419, 1778, 2271, 751, 1377, 18, 2266, 552, 824, 2329, 2287, 1231, 820, 2378, 1223, 1472, 1003, 505, 1040, 1181, 178, 1939, 2053, 10, 1852, 1747, 2088, 881, 1780, 2303, 1692, 93, 1428, 387, 1116, 828, 714, 122, 1612, 2082, 1781, 1039, 1214, 483, 2194, 1951, 1403, 1089, 2132, 2242, 1903, 1065, 955, 305, 769, 1443, 1687, 2006, 1213, 1502, 503, 849, 1322, 85, 2386, 162, 434, 2263, 1546, 2167, 200, 254, 699, 2156, 1243, 1395, 1331, 793, 222, 1869, 684, 728, 1738, 949, 599, 142, 1958, 1442, 832, 2325, 2294, 2, 2031, 886, 973, 813, 726, 1596, 871, 25, 362, 1353, 2278, 136, 919, 1513, 1840, 2094, 1341, 1210, 1901, 1664, 1205, 2052, 322, 1563, 1808, 1171, 1038, 906, 380, 768, 887, 1357, 1583, 336, 1105, 1130, 1072, 1884, 1315, 2380, 1079, 1956, 1604, 2040, 802, 600, 188, 8, 1407, 1730, 1351, 1499, 1344, 876, 1131, 276, 1863, 2073, 1471, 798, 1920, 182, 2087, 987, 2219, 697, 581, 485, 2324, 1397, 1365, 270, 1500, 804, 654, 1002, 1772, 1486, 9, 2127, 1224, 1517, 582, 201, 1722, 1851, 1701, 28, 2102, 51, 2165, 219, 1934, 273, 292, 2240, 944, 1733, 533, 1011, 1757, 1957, 1426, 209, 702, 2122, 1997, 2002, 1174, 1049, 220, 477, 2387, 620, 48, 2331, 834, 2058, 1432, 27, 438, 2302, 63, 827, 1156, 2254, 998, 933, 1640, 34, 1606, 571, 742, 1622, 1557, 84, 1963, 2020, 899, 2183, 1464, 586, 1816, 568, 2101, 2071, 1494, 1251, 2030, 1094, 2332, 2067, 193, 454, 159, 1838, 703, 2147, 1535, 2039, 2041, 1693, 1754, 325, 692, 1830, 7, 377, 1518, 1236, 2046, 1864, 433, 1191, 1673, 2226, 1929, 416, 761, 1422, 1418, 348, 1745, 1430, 1456, 2314, 687, 989, 1703, 1914, 947, 1653, 187, 301, 342, 1561, 1955, 499, 2273, 1218, 1328, 1487, 1053, 1782, 2211, 2124, 856, 290, 1219, 811, 1587, 202, 1186, 1936, 2028, 1999, 1489, 1458, 96, 1856, 1750, 1488, 1792, 1907, 1063, 866, 2125, 2185, 1323, 459, 873, 574, 344, 1759, 514, 1310, 1220, 1417, 2131, 1121, 891, 2049, 2363, 2086, 1090, 1949, 1325, 1688, 691, 160, 1818, 1201, 2050, 1647, 1208, 1959, 1885, 2180, 1084, 171, 723, 207, 1746, 681, 1538, 1616, 522, 1481, 1801, 1537, 2175, 1056, 1646, 1930, 1392, 1810, 1952, 2322, 448, 494, 2048, 77, 2258, 792, 1523, 2306, 1574, 2214, 2173, 374, 1978, 712, 772, 2291, 993, 2172, 1498, 1330, 1335, 241, 2310, 1204, 660, 1188, 277, 753, 161, 1652, 1845, 1719, 1637, 1307, 2280, 1390, 2348, 1202, 1197, 782, 1033, 1674, 1279, 558, 2234, 1995, 186, 403, 1183, 460, 1169, 580, 1474, 1453, 1266, 1683, 247, 1447, 750, 879, 1642, 1424, 980, 924, 367, 472, 332, 1698, 2130, 312, 47, 1839, 2159, 770, 181, 1146, 570, 648, 638, 1399, 609, 1313, 918, 1285, 2103, 227, 123, 311, 420, 40, 1248, 543, 898, 841, 1771, 232, 1125, 585, 481, 1148, 464, 1570, 517, 2061, 1161, 264, 1423, 743, 872, 45, 668, 2134, 81, 926, 1829, 1014, 283, 2150, 1960, 89, 925, 155, 437, 951, 1826, 1848, 1976, 1833, 1695, 905, 180, 426, 1720, 1100, 2369, 1314, 1994, 2012, 1162, 1434, 489, 1827, 2118, 2358, 106, 1800, 282, 67, 120, 1025, 542, 6, 174, 741, 537, 2296, 211, 442, 995, 2288, 2350, 779, 2250, 630, 1175, 787, 1944, 1070, 1975, 512, 354, 911, 1648, 1611, 1339, 1132, 1101, 2201, 2365, 705, 221, 1420, 593, 166, 50, 566, 1184, 13, 2068, 1074, 1740, 1707, 368, 1569, 1828, 1305, 590, 922, 1786, 535, 1704, 2335, 645, 2308, 729, 2113, 910]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **English to Hindi**","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\n    \"facebook/nllb-200-distilled-600M\", src_lang=\"eng_Latn\"\n)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\nmodel=model.to(\"cuda\")\nen_to_hi=[]\nfor i in range(1000):\n    inputs = tokenizer(en[i] , return_tensors=\"pt\").to(\"cuda\")\n\n    translated_tokens = model.generate(\n        **inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"hin_Deva\"], max_length=30\n    )\n    en_to_hi.append(tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0])\n\nwith open(\"en_to_hi1.txt\", \"w\", encoding=\"utf-8\") as file:\n    for lines in en_to_hi:\n        # Write English sentence to file\n        file.write(lines.strip() + \"\\n\")\n        \n\n    ","metadata":{"papermill":{"duration":2337.564851,"end_time":"2024-04-15T06:13:11.386603","exception":false,"start_time":"2024-04-15T05:34:13.821752","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-16T09:25:22.972102Z","iopub.execute_input":"2024-04-16T09:25:22.972439Z","iopub.status.idle":"2024-04-16T09:33:37.362389Z","shell.execute_reply.started":"2024-04-16T09:25:22.972411Z","shell.execute_reply":"2024-04-16T09:33:37.361531Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ca3cec263044ca3ac365dab35116432"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"877693fcd60947ef923ec8a141bb8643"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9530dbc5d92a4ecabff01486e24a82b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f56ed118d644530b702502078c73c61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a45b7ac59b24c86903fcb74512080db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c04aa17247864b36b94fb3c166029467"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32f504da242c49c589ebd1e3fdaa9c9f"}},"metadata":{}},{"name":"stderr","text":"the `lang_code_to_id` attribute is deprecated. The logic is natively handled in the `tokenizer.adder_tokens_decoder` this attribute will be removed in `transformers` v4.38\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Hindi To English**","metadata":{"papermill":{"duration":0.004809,"end_time":"2024-04-15T06:13:11.408193","exception":false,"start_time":"2024-04-15T06:13:11.403384","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\n    \"facebook/nllb-200-distilled-600M\", src_lang=\"hin_Deva\"\n)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\nmodel=model.to(\"cuda\")\nhi_to_en=[]\nfor i in range(1000):\n    inputs = tokenizer(hi[i] , return_tensors=\"pt\").to(\"cuda\")\n\n    translated_tokens = model.generate(\n        **inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"eng_Latn\"], max_length=30\n    )\n    hi_to_en.append(tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0])\n\nwith open(\"hi_to_en1.txt\", \"w\", encoding=\"utf-8\") as file:\n    for lines in hi_to_en:\n        # Write English sentence to file\n        file.write(lines.strip() + \"\\n\")","metadata":{"papermill":{"duration":null,"end_time":null,"exception":false,"start_time":"2024-04-15T06:13:11.413366","status":"running"},"tags":[],"execution":{"iopub.status.busy":"2024-04-16T09:34:37.699725Z","iopub.execute_input":"2024-04-16T09:34:37.700628Z","iopub.status.idle":"2024-04-16T09:42:08.890004Z","shell.execute_reply.started":"2024-04-16T09:34:37.700596Z","shell.execute_reply":"2024-04-16T09:42:08.888969Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# **Hindi to Gujrati**","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\n    \"facebook/nllb-200-distilled-600M\", src_lang=\"hin_Deva\"\n)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\nmodel=model.to(\"cuda\")\nhin_to_guj=[]\nfor i in range(1000):\n    inputs = tokenizer(hi[i] , return_tensors=\"pt\").to(\"cuda\")\n\n    translated_tokens = model.generate(\n        **inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"guj_Gujr\"], max_length=30\n    )\n    hin_to_guj.append(tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0])\n\nwith open(\"hin_to_guj1.txt\", \"w\", encoding=\"utf-8\") as file:\n    for lines in hin_to_guj:\n        # Write English sentence to file\n        file.write(lines.strip() + \"\\n\")","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2024-04-16T09:42:44.150746Z","iopub.execute_input":"2024-04-16T09:42:44.151131Z","iopub.status.idle":"2024-04-16T09:50:59.579428Z","shell.execute_reply.started":"2024-04-16T09:42:44.151099Z","shell.execute_reply":"2024-04-16T09:50:59.578510Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# **Gujrati to Hindi**","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\n    \"facebook/nllb-200-distilled-600M\", src_lang=\"guj_Gujr\"\n)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\nmodel=model.to(\"cuda\")\nguj_to_hin=[]\nfor i in range(1000):\n    inputs = tokenizer(gu[i] , return_tensors=\"pt\").to(\"cuda\")\n\n    translated_tokens = model.generate(\n        **inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"hin_Deva\"], max_length=30\n    )\n    guj_to_hin.append(tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0])\n\nwith open(\"guj_to_hin1.txt\", \"w\", encoding=\"utf-8\") as file:\n    for lines in guj_to_hin:\n        # Write English sentence to file\n        file.write(lines.strip() + \"\\n\")\n        ","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2024-04-16T09:53:28.334584Z","iopub.execute_input":"2024-04-16T09:53:28.335322Z","iopub.status.idle":"2024-04-16T10:01:18.890239Z","shell.execute_reply.started":"2024-04-16T09:53:28.335291Z","shell.execute_reply":"2024-04-16T10:01:18.889457Z"},"trusted":true},"execution_count":6,"outputs":[]}]}